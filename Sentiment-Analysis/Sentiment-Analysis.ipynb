{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re                                       \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_case(str):\n",
    "    return str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "about 30% percent of postings are stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(str):     # do, are ,...\n",
    "    stopWords = set(stopwords.words('english')) \n",
    "    s = \" \"\n",
    "    tokens = word_tokenize(str)\n",
    "    for t in tokens :\n",
    "        if not t in stopWords:\n",
    "            s += t + \" \"\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_numbers(str):\n",
    "    return re.sub(r'\\d+', '', str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The part of the following function that was commented on was not effective. So I commented it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(str):\n",
    "    # t=\"\"\n",
    "    # for s in str.split():\n",
    "    #     if s[0] != \"@\" :\n",
    "    #         t += s + \" \"\n",
    "    return re.sub(r'[^\\w\\s]', '', str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_whitespaces(str):\n",
    "    return str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(str):    #stemming-> stem    goes->go\n",
    "    str = word_tokenize(str)\n",
    "    s = \"\"\n",
    "    for word in str:\n",
    "        s+=PorterStemmer().stem(word)+\" \"\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>RT @cjwallace03: So apparently @apple put MB c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>RT @Jewelz2611 @mashable @apple iphones r 2 ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@mashable @apple iphones r 2 expensive. Most w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>THiS IS WHAT WiLL KiLL APPLE http://t.co/72Jw4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Now all @Apple has to do is get swype on the i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1219</th>\n",
       "      <td>4</td>\n",
       "      <td>RT @ahhfuckitsguss: #twitter can be so useful ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220</th>\n",
       "      <td>4</td>\n",
       "      <td>My 3 biggest obsessions: #twitter #dancemoms a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>0</td>\n",
       "      <td>My mentions aren't showing properly ... PAY AT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>4</td>\n",
       "      <td>#twitter is jumpin as usual :)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1223</th>\n",
       "      <td>4</td>\n",
       "      <td>My Facebook messed up and I had to make a new ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1224 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0                                                  1\n",
       "0     0  RT @cjwallace03: So apparently @apple put MB c...\n",
       "1     0  RT @Jewelz2611 @mashable @apple iphones r 2 ex...\n",
       "2     0  @mashable @apple iphones r 2 expensive. Most w...\n",
       "3     0  THiS IS WHAT WiLL KiLL APPLE http://t.co/72Jw4...\n",
       "4     4  Now all @Apple has to do is get swype on the i...\n",
       "...  ..                                                ...\n",
       "1219  4  RT @ahhfuckitsguss: #twitter can be so useful ...\n",
       "1220  4  My 3 biggest obsessions: #twitter #dancemoms a...\n",
       "1221  0  My mentions aren't showing properly ... PAY AT...\n",
       "1222  4                     #twitter is jumpin as usual :)\n",
       "1223  4  My Facebook messed up and I had to make a new ...\n",
       "\n",
       "[1224 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"SandersPosNeg.csv\", header=None, sep=\"\\t\" )\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preprocessing:\n",
    "\n",
    "remove_whitespaces() and lower_case() are not effective in TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       RT cjwallac So appar appl put MB cap sm new up...\n",
       "1       RT jewelz mashabl appl iphon r expens most wen...\n",
       "2       mashabl appl iphon r expens most went w htcgal...\n",
       "3        thi IS what will kill appl httptcojwzc rip appl \n",
       "4                   now appl get swype iphon crack iphon \n",
       "                              ...                        \n",
       "1219    RT ahhfuckitsguss twitter use let feel cant re...\n",
       "1220    My biggest obsess twitter dancemom desperateho...\n",
       "1221    My mention arent show properli pay attent twit...\n",
       "1222                                twitter jumpin usual \n",
       "1223    My facebook mess I make new one add haha least...\n",
       "Name: 1, Length: 1224, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df[1] = df[1].apply(lower_case)\n",
    "df[1] = df[1].apply(remove_numbers)                \n",
    "df[1] = df[1].apply(remove_punctuation)\n",
    "df[1] = df[1].apply(remove_whitespaces)\n",
    "df[1] = df[1].apply(remove_stop_words)\n",
    "df[1] = df[1].apply(stemming)            \n",
    "df[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1224x3234 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 12335 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer                         # Vectorize fd\n",
    "from sklearn.model_selection import ShuffleSplit, cross_val_score                   # 10fold cross validation\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X = tfidf_vectorizer.fit_transform(df[1])\n",
    "Y = df[0]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "def naive_bayes(cv):\n",
    "    clf = MultinomialNB(alpha=0.48)\n",
    "    naiveBayes = cross_val_score(clf, X, df[0], cv=cv)  #naive_bayes for each permutation\n",
    "    print(naiveBayes*100)\n",
    "    print(naiveBayes.mean()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "def mlp(cv):\n",
    "    clf = MLPClassifier(hidden_layer_sizes=(80,), random_state=0, max_iter=150, alpha=0.001)\n",
    "    NB_result = cross_val_score(clf, X, df[0], cv=cv)\n",
    "    print(NB_result*100)\n",
    "    print(NB_result.mean()*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_splits = k = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[85.71428571 86.12244898 86.12244898 80.         84.89795918 82.44897959\n",
      " 83.26530612 86.53061224 83.26530612 80.81632653]\n",
      "83.91836734693878\n"
     ]
    }
   ],
   "source": [
    "Random_permutation_cross_validator = ShuffleSplit(n_splits = 10, test_size=0.2, random_state=0)      #10 permutation\n",
    "naiveBayes = naive_bayes(Random_permutation_cross_validator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[86.93877551 88.16326531 86.12244898 79.59183673 86.53061224 86.12244898\n",
      " 84.89795918 86.12244898 83.67346939 84.48979592]\n",
      "85.26530612244899 %\n"
     ]
    }
   ],
   "source": [
    "Random_permutation_cross_validator = ShuffleSplit(n_splits = 10, test_size=0.2, random_state=0)      #10 permutation\n",
    "mlp(Random_permutation_cross_validator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP is slower and a bit better. So there is a trade-off between time and accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now another dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Watching by myself  #tweetdebate Not drinking ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>@ahg3 @MichDot Yeah, slime was actually my sec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Preparing to have a heart attack #tweetdebate,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>no debate moderators under 50, sorry  #tweetde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@current Now staring at black screen on http:/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1901</th>\n",
       "      <td>4</td>\n",
       "      <td>@Imarilove Yes, He did. I liked the eye contac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1902</th>\n",
       "      <td>4</td>\n",
       "      <td>Bloggers right; mccain won because it is his i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1903</th>\n",
       "      <td>4</td>\n",
       "      <td>Anyone trying to say John McCain is a liar, su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1904</th>\n",
       "      <td>4</td>\n",
       "      <td>CNN post debate polling is saying the debate w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1905</th>\n",
       "      <td>4</td>\n",
       "      <td>Very big Obama lead in the CNN post debate pol...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1906 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0                                                  1\n",
       "0     0  Watching by myself  #tweetdebate Not drinking ...\n",
       "1     0  @ahg3 @MichDot Yeah, slime was actually my sec...\n",
       "2     0     Preparing to have a heart attack #tweetdebate,\n",
       "3     0  no debate moderators under 50, sorry  #tweetde...\n",
       "4     0  @current Now staring at black screen on http:/...\n",
       "...  ..                                                ...\n",
       "1901  4  @Imarilove Yes, He did. I liked the eye contac...\n",
       "1902  4  Bloggers right; mccain won because it is his i...\n",
       "1903  4  Anyone trying to say John McCain is a liar, su...\n",
       "1904  4  CNN post debate polling is saying the debate w...\n",
       "1905  4  Very big Obama lead in the CNN post debate pol...\n",
       "\n",
       "[1906 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"OMD.csv\", header=None, sep=\"\\t\")\n",
    "d0 = []\n",
    "d1 = []\n",
    "for d in df.values.tolist() :\n",
    "    d0.append(d[0][0])\n",
    "    d1.append(d[0][2:])\n",
    "\n",
    "df = pd.DataFrame(list(zip(d0, d1)))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preprocessing:\n",
    "Those who commented either had no effect or made it worse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df[1] = df[1].apply(lower_case)                    \n",
    "df[1] = df[1].apply(remove_numbers)                \n",
    "df[1] = df[1].apply(remove_punctuation)\n",
    "# df[1] = df[1].apply(remove_whitespaces)            \n",
    "df[1] = df[1].apply(remove_stop_words)\n",
    "# df[1] = df[1].apply(stemming)                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X = tfidf_vectorizer.fit_transform(df[1])\n",
    "Random_permutation_cross_validator = ShuffleSplit(n_splits = 10, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naive bayes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[76.43979058 78.53403141 79.05759162 72.77486911 74.34554974 73.29842932\n",
      " 78.27225131 76.70157068 77.48691099 77.22513089]\n",
      "76.41361256544504\n"
     ]
    }
   ],
   "source": [
    "\n",
    "naiveBayes = naive_bayes(Random_permutation_cross_validator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[74.86910995 78.27225131 79.58115183 76.70157068 76.96335079 74.08376963\n",
      " 75.91623037 77.22513089 78.27225131 76.96335079]\n",
      "76.88481675392669 %\n"
     ]
    }
   ],
   "source": [
    "mlp(Random_permutation_cross_validator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes is really faster. and The difference between the accuracy of naive Bayes and MLP is small. So in this case Naive bayes is better"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
